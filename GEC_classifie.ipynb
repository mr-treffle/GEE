{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qs7nehuIOWV1"
   },
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFfpS-H8OiPn"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2665,
     "status": "ok",
     "timestamp": 1595463472796,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "Y1cSADRM1KvF",
    "outputId": "d8c5c5bf-7da1-4129-d42d-ee5fc81fd61b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/           glove.6B.50d.txt\n",
      " conll14st-preprocessed.m2   كتاب-اللغة-الفرنسية-المدرسي-سنة-خامسة-ابتدائي.pdf\n"
     ]
    }
   ],
   "source": [
    "%ls drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1719,
     "status": "ok",
     "timestamp": 1595465974216,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "7D5uNE4rPGep",
    "outputId": "9158b5d7-167a-4ae2-ad66-5b85e5680d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2545,
     "status": "ok",
     "timestamp": 1595465024080,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "EjXnzeoeOWV4"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "\n",
    "import os\n",
    "import sys,re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, GlobalMaxPool1D, Bidirectional, Conv1D\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Embedding, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOuYaCFhOWWA"
   },
   "source": [
    "some configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1595465028238,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "n9GxihPyOWWB"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ka9rSkf0OWWG"
   },
   "source": [
    "load in pre-trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3606,
     "status": "error",
     "timestamp": 1595465041566,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "eBfQAIiOOWWH",
    "outputId": "05cf46ab-764c-43ea-c4dc-b9f1e82896c0"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-126f4ea9bd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/glove.6B.50d.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# is just a space-separated text file in the format:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# word vec[0] vec[1] vec[2] ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "f=open('/content/drive/My Drive/glove.6B.50d.txt','r')\n",
    "lines = f.readlines()\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "for line in lines:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  vec = np.asarray(values[1:], dtype='float32')\n",
    "  word2vec[word] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dti5vTIGOWWO",
    "outputId": "a63a6a68-74ed-40bd-c547-102cf6189f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6tZ3IVtOWWT"
   },
   "source": [
    "prepare text samples and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1595466119012,
     "user": {
      "displayName": "Hassan Ch",
      "photoUrl": "",
      "userId": "16111454146617779523"
     },
     "user_tz": -60
    },
    "id": "wUUwEUYfOWWU"
   },
   "outputs": [],
   "source": [
    "sentences = np.empty(0,dtype='object')\n",
    "targets = np.zeros((0,28))\n",
    "labels = {\"Vt\":0,\"Vm\":1,\"V0\":2,\"Vform\":3,\"SVA\":4,\"ArtOrDet\":5,\"Nn\":6,\"Npos\":7,\"Pform\":8,\"Pref\":9,\"Prep\":10,\"Wci\":11,\"Wa\":12,\"Wform\":13,\"Wtone\":14,\"Srun\":15,\"Smod\":16,\"Spar\":17,\"Sfrag\":18,\"Ssub\":19,\"WOinc\":20,\"WOadv\":21,\"Trans\":22,\"Mec\":23,\"Rloc\":24,\"Cit\":25,\"Others\":26,\"Um\":27}\n",
    "i=0\n",
    "f=open('/content/drive/My Drive/conll14st-preprocessed.m2','r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrr-LbUP4ecS"
   },
   "outputs": [],
   "source": [
    "line = f.readline()\n",
    "while line:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        # print(line)\n",
    "        if re.search(\"^S\",line):\n",
    "            a=np.empty(1,dtype='object')\n",
    "            a[0]=line[2:]\n",
    "            sentences=np.concatenate([sentences,a])\n",
    "            b=np.zeros((1,28))\n",
    "            targets=np.concatenate([targets,b])\n",
    "            i=i+1\n",
    "        elif re.search(\"^A\",line):\n",
    "            # print(\"found annotation\")\n",
    "            for key in labels:\n",
    "                # print(labels.get(key))\n",
    "                if re.search(key,line):\n",
    "                    # print(labels.get(key))\n",
    "                    targets[i-1,labels.get(key)]=1\n",
    "                    break\n",
    "    line=f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmeHjwdEOWWa",
    "outputId": "6a7b8785-48ac-4b8a-f1ec-43d688a26c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0.]\n",
      "found line 57151\n"
     ]
    }
   ],
   "source": [
    "print(targets[3])\n",
    "print(targets[5])\n",
    "print(\"found line\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_qUuAuqOWWi"
   },
   "source": [
    "convert the sentences (strings) into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDuB0Fn9OWWj",
    "outputId": "9d809724-40f0-45df-9e16-d1f2cfca4c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...\n"
     ]
    }
   ],
   "source": [
    "print('Tokenization...')\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pv3A_X7OOWWo",
    "outputId": "a48ec855-a650-4e2c-958f-71164b4ecbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence[0]:  [1113, 7, 7661, 228]\n",
      "max sequence length: 131\n",
      "min sequence length: 0\n",
      "Found 25893 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print(\"sequence[0]: \", sequences[0])\n",
    "\n",
    "print(\"max sequence length:\", max(len(s) for s in sequences))\n",
    "print(\"min sequence length:\", min(len(s) for s in sequences))\n",
    "# s = sorted(len(s) for s in sequences)\n",
    "# print(\"median sequence length:\", s[len(s) // 2])\n",
    "#\n",
    "# print(\"max word index:\", max(max(seq) for seq in sequences if len(seq) > 0))\n",
    "\n",
    "print('Found %s unique tokens.' % len(word2idx))\n",
    "# print(next(iter(word2idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIAMP8WoOWWs"
   },
   "source": [
    "pad sequences so that we get a N x T matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt98WWGHOWWt",
    "outputId": "337964be-b89e-4ee1-9555-94ee25745208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences...\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences...')\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UV1XgRmOWWy",
    "outputId": "793d9b32-d956-4f61-83ed-f16899752a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0 1113    7\n",
      " 7661  228]\n",
      "Shape of data tensor: (57151, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"data[0]\", data[0])\n",
    "print('Shape of data tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogDSPjq2OWW2"
   },
   "source": [
    "prepare embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoUGfaEBOWW3",
    "outputId": "9a343325-02d8-48a0-fbf6-bff03201ec9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n",
      "len word2idx 25893\n"
     ]
    }
   ],
   "source": [
    "print('Filling pre-trained embeddings...')\n",
    "print(\"len word2idx\", len(word2idx))\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkykwGWLOWW7",
    "outputId": "5563e079-c28e-4ec5-a2fd-7a4453d61514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_matrix shape: (20000, 50)\n",
      "1113\n",
      "embedding_matrix[1113] [ 0.66447997  0.059328   -0.10265     0.072485   -0.042958    0.62238002\n",
      " -0.061768   -0.76239997  0.18791001  0.50511998 -0.18424     0.010916\n",
      " -0.21409     0.29516    -0.18311     0.080493    0.69437999  0.26245001\n",
      "  0.48195001 -0.66535997  0.67246997 -0.20181    -0.47898    -0.079556\n",
      "  0.085443   -0.67527997 -0.38523999 -0.027527    0.80712998  0.10879\n",
      "  3.27469993  0.16201    -0.21815    -1.19159997 -0.70274001  0.60671997\n",
      " -0.65700001  0.065899   -0.41716999 -0.25497001 -0.26298001 -0.25551\n",
      " -0.065865    0.08621    -0.28215     0.32980999  0.075665    0.013673\n",
      " -0.16734999 -0.17380001]\n"
     ]
    }
   ],
   "source": [
    "print(\"embedding_matrix shape:\", embedding_matrix.shape)\n",
    "print(word2idx.get(\"creating\"))\n",
    "print(\"embedding_matrix[1113]\", embedding_matrix[1113])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBbKBx9vOWXA"
   },
   "source": [
    "load pre-trained word embeddings into an Embedding layer <br/>\n",
    "note that we set trainable = False so as to keep the embeddings fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10w8zi8kOWXB",
    "outputId": "ed70deda-be97-4d14-a057-2e0e5574ee70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Embedding layer ...\n"
     ]
    }
   ],
   "source": [
    "print('Building Embedding layer ...')\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=MAX_SEQUENCE_LENGTH,\n",
    "  trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CNu6dUDDOWXI"
   },
   "source": [
    "Building model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGsHv505OWXI"
   },
   "outputs": [],
   "source": [
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(input_)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(28, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(input_, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NGShW3gOWXM"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "   loss='binary_crossentropy',\n",
    "   optimizer='rmsprop',\n",
    "   metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh7nVbUuOWXT"
   },
   "outputs": [],
   "source": [
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data,\n",
    "  targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6ucpzwlOWXX"
   },
   "source": [
    "plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_wsZFcwOWXY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lF88EaCgOWXc"
   },
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9qNfp9sOWXf"
   },
   "outputs": [],
   "source": [
    "p = model.predict(data)\n",
    "aucs = []\n",
    "for j in range(6):\n",
    "    auc = roc_auc_score(targets[:,j], p[:,j])\n",
    "    aucs.append(auc)\n",
    "print(np.mean(aucs))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GEC_classifie.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
